# -*- coding: utf-8 -*-
"""ResessionOFUKExtractiveSummarize.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zj7nQAvp0iR77MuAbGj6EBzi1FTdv90b
"""

import nltk
import bs4
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize, sent_tokenize
import requests
from bs4 import BeautifulSoup
nltk.download('stopwords')
nltk.download('punkt')

def GetText(url):
    site = requests.get(url).text #Request html object from url
    soup = BeautifulSoup(site, "html.parser") #Create BeautifulSoup object
    text ="" 
    for j in soup.find_all("p"): #Find all paragraph tags within the html page
        text += j.get_text() #Get text from each paragraph tag in document and append to 'text' variable
    return text


def GenerateWordFrequencyDistribution(text):
    stops = set(stopwords.words("english"))
    words = word_tokenize(text) #tokenize text by words
    freqTable = dict()

    for word in words: #Itterate through all words in text
        word = word.lower() #Convert word to lowercase
        if word not in stops: #Ignore stopwords
            if word in freqTable:
                freqTable[word] += 1 #Add one to the word frequency if it has already been added to before
            else:
                freqTable[word] = 1  #Set the word frequency to one if it has not already been added to before
    return freqTable


def CalculateSentenceImportance (text, freqTable):
    sents = sent_tokenize(text)
    sentScores = dict()
    
    for sent in sents:
        for word, freq in freqTable.items():
            if word in sent.lower():
                if sent in sentScores:
                    sentScores[sent] += freq #Add the frequency of a word occuring to the sentence score if it has been added to before
                else: 
                    sentScores[sent] = freq  #Set score of a sentence to the score of the first word occuring in the sentence
    return sentScores, sents


def CalculateAverageSentenceImportance (sentScores):
    sumValues = 0
    for sentence in sentScores:
        sumValues += sentScores[sentence] #Calculate total sentence values
        
    return (sumValues / len(sentScores)) #Return average sentence value


def PerformExtractiveSummarisation(sentences, sentScores, average):
    summary = ""
    for sent in sentences:
        if (sentScores[sent] > (1.5 * average)): #Check if the sentence has a score greater than 1.5 times the average.
            summary += sent + " "
            
    return summary

#Hardcode a url to summarise
Url ="https://www.reuters.com/world/uk/uk-economy-grows-q4-avoids-recession-ons-2023-03-31/#:~:text=LONDON%2C%20March%2031%20(Reuters),but%20falling%20investment%20by%20businesses."

#Get articles text
Text = GetText(Url)

#Generate a frequency distribution based on previously acquired text
FreqTable = GenerateWordFrequencyDistribution(Text)
FreqTable

#Generate sentence values for each sentence in text back on frequency of work occurance.
sentScores, Sentences = CalculateSentenceImportance(Text, FreqTable)
print(sentScores, Sentences)

#Calculate the average sentence importance
AverageValue = CalculateAverageSentenceImportance(sentScores)
AverageValue

#Perform Extractive Summarisation on sentences and determine which sentences to keep and which to remove, returns a summary.
Summary = PerformExtractiveSummarisation(Sentences,sentScores, AverageValue)

print(Summary)