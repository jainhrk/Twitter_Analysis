# -*- coding: utf-8 -*-
"""Twitter_EDA_SeptAtt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oFRq5C_ukwYvcOIdOtKiFHLa31bv18zc
"""

import numpy as np
import pandas as pd

import numpy             as np
import pandas            as pd
import matplotlib.pyplot as plt
import seaborn           as sns
import plotly.graph_objs as go
import plotly.express    as px 
import nltk
import re
import string

from scipy.stats import norm
from wordcloud   import WordCloud, STOPWORDS

import warnings
warnings.filterwarnings("ignore")
from wordcloud import WordCloud,STOPWORDS
stopwords = set(STOPWORDS)

from textblob import TextBlob
import re
from collections import Counter

from sklearn.metrics import classification_report,accuracy_score,confusion_matrix
from IPython.display import Markdown as md

from google.colab import drive 
drive.mount('/content/gdrive')
data = pd.read_csv('gdrive/My Drive/Colab Notebooks/attaa.csv')

data.head()

data.info()

data.describe()

print("There are {} rows and {} columns in the dataset.".format(data.shape[0],data.shape[1]))

from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
nltk.download('stopwords')
punc=string.punctuation
stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()
lemmatizer = WordNetLemmatizer()
nltk.download('wordnet')
nltk.download('punkt')
def clean_text(text):
    
    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation
    and remove words containing numbers.'''
    
    text = text.lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    
    #Removing stopwords
    text=" ".join([word for word in str(text).split() if word not in stop_words])
    
    #Stemming
    text = " ".join([stemmer.stem(word) for word in text.split()])
    
    #Lemmatization
    text = " ".join([lemmatizer.lemmatize(word) for word in text.split()])
    
    return text
# Apply the clean_text function to the 'text' column of the data
data['Text'] = data['Text'].apply(lambda x: clean_text(x))

def remove_emoji(text):
    emoji_pattern = re.compile("["
                           u"\U0001F600-\U0001F64F"  # emoticons
                           u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                           u"\U0001F680-\U0001F6FF"  # transport & map symbols
                           u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                           u"\U00002702-\U000027B0"
                           u"\U000024C2-\U0001F251"
                           "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r'', text)

data['Text']=data['Text'].apply(lambda x: remove_emoji(x))

data.head()

data.tail()

Text = ",".join(review for review in data.Text if 'September' not in review and 'attack' not in review and 'Sept atta' not in review)# Join all the cleaned text data into a single string
wordcloud = WordCloud(max_words=200, colormap='Set3',background_color="black").generate(Text)# Generate a word cloud from the cleaned text data
plt.figure(figsize=(15,10))# Set up a plot to display the word cloud
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.figure(1,figsize=(12, 12))
plt.title('Prevalent words in tweets',fontsize=19)# Add a title to the plot and show it
plt.show()

plt.figure(figsize=(10,12))
sns.barplot(x=data["Location"].value_counts().values[0:10],# Create a bar plot of the top 10 countries with the most tweets
            y=data["Location"].value_counts().index[0:10]);
plt.title("Top 10 Countries with maximum tweets",fontsize=14)
plt.xlabel("Number of tweets",fontsize=14)
plt.ylabel("Place",fontsize=14)
plt.show()

plt.figure(figsize=(17, 5))
sns.heatmap(data.isnull(), cbar=True, cmap='Paired_r')
plt.xlabel("Column_Name", size=14, weight="bold")
plt.title("Places of missing values in column",fontweight="bold",size=14)
plt.show()

def unique_values_funct(data_frame):
    unique_dataframe = pd.DataFrame()
    unique_dataframe['Features'] = data_frame.columns
    uniques = []
    for col in data_frame.columns:
        u = data_frame[col].nunique()
        uniques.append(u)
    unique_dataframe['Uniques'] = uniques
    return unique_dataframe

udf = unique_values_funct(data)

f, ax = plt.subplots(1,1, figsize=(10,5))
colors = ['blue', 'green', 'orange', 'red', 'purple', 'yellow', 'pink', 'brown', 'gray', 'black']
sns.barplot(x=udf['Features'], y=udf['Uniques'], alpha=0.8, palette=colors)
plt.title('Bar plot for unique values in each column', fontsize=14)
plt.ylabel('Unique values', fontsize=14)
plt.xlabel('Columns', fontsize=14)
plt.xticks(rotation=90)
plt.show()

data["num of words in text"] = data["Text"].apply(lambda x: len(x))
plt.figure(figsize=(10,7))
sns.kdeplot(data["num of words in text"])
plt.title("Distribution of words in text column")
plt.xlabel("Number of words")
plt.show()

username_count = data['Username'].value_counts().reset_index().rename(columns={
    'Username':'tweet_count','index':'Username'})

plt.figure(figsize=(8, 10))
sns.barplot(y='Username',x='tweet_count',data=username_count.head(20))
y=username_count['tweet_count'].head(20)
for index, value in enumerate(y):
    plt.text(value, index, str(value),fontsize=12)
plt.title('Users with maximum tweets',weight='bold', size=13)
plt.ylabel('Username', size=12, weight='bold')
plt.xlabel('TweetCount', size=12, weight='bold')
plt.show()

plt.figure(figsize=(15,5))
src = data['Source'].value_counts().sort_values(ascending=False)
source = src.head(10)
source.plot.bar(color=['black', 'blue', 'red', 'gold','orange','teal','green','turquoise','silver','#f542f5'])
plt.title('Platform with maximum number of tweets',size=13)
plt.xlabel('User Platform',size=13)
plt.ylabel('Tweet Count',size=13)
plt.show()

pla = data['Source'][data['Location'] == 'United States'].value_counts().sort_values(ascending=False)
explode = (0, 0.1, 0, 0,0.01) 
plt.figure(figsize=(8,8))
pla[0:5].plot(kind = 'pie', title = '5 Most Tweet Sources used in United States', autopct='%1.1f%%',shadow=True,explode = None)
plt.show()

pla = data['Source'][data['Location'] == 'United Kingdom'].value_counts().sort_values(ascending=False)
explode = (0, 0.1, 0, 0,0.01) 
plt.figure(figsize=(8,8))
pla[0:5].plot(kind = 'pie', title = '5 Most Tweet Sources used in United Kingdom', autopct='%1.1f%%',shadow=True,explode = None)
plt.show()

pla = data['Source'][data['Location'] == 'India'].value_counts().sort_values(ascending=False)
explode = (0, 0.1, 0, 0,0.01) 
plt.figure(figsize=(8,8))
pla[0:5].plot(kind = 'pie', title = '5 Most Tweet Sources used in India', autopct='%1.1f%%',shadow=True,explode = None)
plt.show()

pla = data['Source'][data['Location'] == 'Australia'].value_counts().sort_values(ascending=False)
explode = (0, 0.1, 0, 0,0.01) 
plt.figure(figsize=(8,8))
pla[0:5].plot(kind = 'pie', title = '5 Most Tweet Sources used in Australia', autopct='%1.1f%%',shadow=True,explode = None)
plt.show()

!pip install gmplot

import geopy
from geopy.geocoders import Nominatim

# Create a geolocator object
geolocator = Nominatim(user_agent='my_app')

def get_latitude(location):
    """Get the latitude of a location using its name."""
    try:
        # Try to geolocate the location
        location = geolocator.geocode(location)
        # Extract the latitude from the location object
        latitude = location.latitude
    except:
        # If geolocation fails, set latitude to None
        latitude = None
    return latitude

from geopy.geocoders import Nominatim

geolocator = Nominatim(user_agent="attaa")  # replace "my_app" with your own user agent string
latitudes = []
longitudes = []

for location in locations:
    try:
        location = geolocator.geocode(location)
        latitudes.append(location.latitude)
        longitudes.append(location.longitude)
    except:
        latitudes.append(None)
        longitudes.append(None)

# Create a Google Maps plot centered on the mean of the latitudes and longitudes
gmap = gmplot.GoogleMapPlotter(np.mean(latitudes), np.mean(longitudes), 5)

# Plot the heatmap
gmap.heatmap(latitudes, longitudes)

# Save the map as an HTML file
gmap.draw('heatmap2.html')